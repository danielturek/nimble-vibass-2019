---
title: "Programming with models: Writing nimbleFunctions with models"
subtitle: "Valencia International Bayesian Analysis Summer School Workshop"
output: html_document
---




# Introduction

*nimbleFunctions* are at the heart of NIMBLE. They are the way that algorithms are implemented. They can also be used for

 - user-defined BUGS distributions (already seen),
 - user-defined BUGS functions (more-or-less seen)
 - user-defined MCMC samplers (coming soon), and
 - compiling parts of R (already seen), without reference to a model.

But their main purpose is providing a way for developers to implement algorithms.

# Components of a nimbleFunction

NIMBLE uses the concept of *two-stage evaluation* from computer science to run a model-specific algorithm based on model-generic algorithm code. The first stage of evaluation specializes the algorithm to the model of interest via *setup* code. The second stage runs the algorithm via *run* code. 

Thus, a nimbleFunction has two parts:

 - setup code: used to tailor the algorithm to a particular model structure. Often this involves determining dependencies amongst nodes in the model and setting up storage using *modelValues*
 - run code: the guts of the algorithm, written generically so it will apply to any (appropriate) model

Setup code is written as a R function, using R code, usually including NIMBLE's special functions for querying the model structure (see the <a href="4.5_model_structure_slides.html" target="_blank" style="color: blue">module on querying model_structure</a>). 

Run code is written using the NIMBLE *domain-specific language* (DSL). While this is formally a language distinct from R, you can just think of it as a subset of R, enhanced with some functions for operating on the model (see the <a href="4.4_operating_model_slides.html" target="_blank" style="color: blue">module on operating a model</a>). 

# Some syntax for nimbleFunctions

Here are some of the functions you may use in the run function of a nimbleFunction:

 - *returnType*, e.g., ```returnType(double(1))``` for a vector of reals
 - *length*, e.g., ```length(x)``` to determine the length of a run-time argument *x*
 - *numeric*, *matrix* and *array* e.g., ```result <- numeric(n, init = 1.0)``` to create a vector of reals called *result* initialized with values of 1.0
 - model member functions *calculate*, *simulate*, *getLogProb*, *calculateDiff* and *getParam* to manipulate the model
 - direct access to nodes or variables in a model using typical R syntax, e.g., ```model[[myNode]] <- rnorm(1)```
 - *values()* and *copy()* (or, equivalently, *nimCopy*) to copy values
 - *print()* and *cat()*
 - basic math, including vectorized math and some linear algebra
 - random number generation functions, e.g., ```rnorm(1, 100, 5)``` 
 - calling out to arbitrary R or C/C++ code with *nimbleRcall()* and *nimbleExternalCall()*
 - *nimbleList* data structures.


Chapter 10 of the <a href="http://r-nimble.org/manuals/NimbleUserManual.pdf" target="_blank" style="color: blue">NIMBLE User Manual</a> describes the syntax for *run* code in detail, including lots of neat functionality such as using nested nimbleFunctions and having multiple run-time functions (i.e., class methods) as part of a nimbleFunction. We'll see more of that in future modules.

nimbleFunctions use **pass-by-reference** not R style **pass-by-value**, so be careful about modifying an object and then using it elsewhere.
  

# A basic example: empirical Bayes / maximum marginal likelihood

Let's consider how we would optimize the parameters in a model using a nimbleFunction. Basically, we'll just construct an objective function that we can then pass to R's *optim* function to do the actual numerical optimization. (NIMBLE also has an `optim()` that you can use within a nimbleFunction.)

This amounts to setting things up to find the posterior mode of a model; this is generally a reasonable thing to do only for models with a small number of parameters and without hierarchical structure. That sounds restrictive, but if you can marginalize over latent process values, then we're doing empirical Bayes.

# A nimbleFunction for the litters marginalized model


```r
objective <- nimbleFunction(
    setup = function(model) {
          # ordinarily we would do stuff here, but in this case
          # we only need make the nimbleFunction aware of the model
          },
    run = function(par = double(1)) {
        returnType(double(0))
        model[['a']] <<- exp(par[1:2])
        model[['b']] <<- exp(par[3:4])
        ans <- model$calculate()
        return(ans)
    }
)
```

This is actually a nimbleFunction *generator* -- we can't run it yet -- we need to create a specialized instance of the nimbleFunction that is tailored for some model, in our case the marginalized litters model. 

# Specializing the nimbleFunction - first set up the model of interest



First let's build the marginalized litters model again.


```r
dbetabin <- nimbleFunction(
    run = function(x = double(0), alpha = double(0), beta = double(0), size = double(0), 
        log = integer(0, default = 0)) {
        
        returnType(double(0))
        logProb <- lgamma(size+1) - lgamma(x+1) - lgamma(size - x + 1) +
            lgamma(alpha + beta) - lgamma(alpha) - lgamma(beta) +
            lgamma(x + alpha) + lgamma(size - x + beta) - lgamma(size + alpha + beta)
        if(log) return(logProb)
        else return(exp(logProb))
    })

rbetabin <- nimbleFunction(
    run = function(n = integer(0), alpha = double(0), beta = double(0), size = double(0)) {
        returnType(double(0))
        if(n != 1) print("rbetabin only allows n = 1; using n = 1.")
        p <- rbeta(1, alpha, beta)
        return(rbinom(1, size = size, prob = p))
    })
```


```r
littersMargCode <- nimbleCode({
  for (i in 1:G) {
     for (j in 1:N) {
     	 # (marginal) likelihood (data model)
        r[i,j] ~ dbetabin(a[i], b[i], n[i,j])
     }
     # prior for hyperparameters
     a[i] ~ dgamma(1, .001)
     b[i] ~ dgamma(1, .001)
   }
})
```

```r
G <- 2
N <- 16
n <- matrix(c(13, 12, 12, 11, 9, 10, 
              9, 9, 8, 11, 8, 10, 13, 10, 12, 9, 10, 9, 10, 5, 9, 9, 13, 
              7, 5, 10, 7, 6, 10, 10, 10, 7), nrow = 2)
r <- matrix(c(13, 12, 12, 11, 9, 10, 9, 9, 8, 10, 8, 9, 
     12, 9, 11, 8, 9, 8, 9, 4, 8, 7, 11, 4, 4, 5, 5, 3, 7, 3, 7, 0), 
     nrow = 2)
              
littersConsts <- list(G = G, N = N, n = n)
littersData <- list(r = r)
littersInits <- list( a = c(2, 2), b=c(2, 2) )

littersMargModel <- nimbleModel(littersMargCode, 
          data = littersData, constants = littersConsts, inits = littersInits)
```

```
## defining model...
```

```
## Registering the following user-provided distributions: dbetabin .
## NIMBLE has registered dbetabin as a distribution based on its use in BUGS code. Note that if you make changes to the nimbleFunctions for the distribution, you must call 'deregisterDistributions' before using the distribution in BUGS code for those changes to take effect.
```

```
## building model...
```

```
## setting data and initial values...
```

```
## running calculate on model (any error reports that follow may simply reflect missing values in model variables) ... 
## checking model sizes and dimensions...
## model building finished.
```

# Specializing the nimbleFunction to the model


```r
rObjective <- objective(littersMargModel)

## remember to compile model first:
cLittersMargModel <- compileNimble(littersMargModel)
```

```
## compiling... this may take a minute. Use 'showCompilerOutput = TRUE' to see C++ compilation details.
```

```
## compilation finished.
```

```r
cObjective <- compileNimble(rObjective, project = littersMargModel)
```

```
## compiling... this may take a minute. Use 'showCompilerOutput = TRUE' to see C++ compilation details.
## compilation finished.
```

Now let's try using it.


```r
system.time(optR <- optim(log(rep(1,4)),
                          rObjective$run,
                          control = list(fnscale = -1)))
```

```
##    user  system elapsed 
##   2.803   0.026   2.839
```

```r
system.time(optC <- optim(log(rep(1,4)),
                          cObjective$run,
                          control = list(fnscale = -1)))
```

```
##    user  system elapsed 
##   0.008   0.001   0.008
```

```r
optR
```

```
## $par
## [1]  3.5802268  0.4638447  1.4091323 -0.5817455
## 
## $value
## [1] -80.46196
## 
## $counts
## function gradient 
##      333       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL
```

```r
optC
```

```
## $par
## [1]  3.5802268  0.4638447  1.4091323 -0.5817455
## 
## $value
## [1] -80.46196
## 
## $counts
## function gradient 
##      333       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL
```

```r
exp(optC$par)
```

```
## [1] 35.8816770  1.5901760  4.0924031  0.5589219
```

# Writing generic functions

Let's look back at our nimbleFunction objective function. What stops it from being usable on any model?


```r
objective <- nimbleFunction(
    setup = function(model, target) {
          ## we'll start putting stuff here soon, I promise!
          },
    run = function(par = double(1)) {
        returnType(double(0))
        values(model, target) <<- exp(par)
        ans <- model$calculate()
        return(ans)
    }
)
```

# Writing generic functions - querying model structure

Calculating the density for all model nodes is not necessary for this optimization, as any nodes that do not depend on the target parameters do not play a role in the optimization.


```r
objective <- nimbleFunction(
    setup = function(model, target) {
          calcNodes <- model$getDependencies(target)
          },
    run = function(par = double(1)) {
        returnType(double(0))
        values(model, target) <<- exp(par)
        ans <- model$calculate(calcNodes)
        return(ans)
    }
)
```


(Of course for maximum marginal likelihood we'd generally expect that the entire model probability density would be calculated.)


```r
rObjective <- objective(littersMargModel, c('a', 'b'))  ## or c('a[1]','a[2]','b[1]','b[2]')
cObjective <- compileNimble(rObjective, project = littersMargModel)
```

```
## compiling... this may take a minute. Use 'showCompilerOutput = TRUE' to see C++ compilation details.
```

```
## compilation finished.
```

```r
optC <- optim(log(rep(1,4)), cObjective$run, control = list(fnscale = -1))
optC
```

```
## $par
## [1]  3.5802268  0.4638447  1.4091323 -0.5817455
## 
## $value
## [1] -80.46196
## 
## $counts
## function gradient 
##      333       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL
```

